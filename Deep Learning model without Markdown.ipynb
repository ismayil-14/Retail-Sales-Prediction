{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing essential Datasets and Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "awH3F0Ss5zDM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_17792\\292587646.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9G1sdZNz6Agc"
   },
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('preprocessed_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "iF0Q9dl26xBL",
    "outputId": "113b6604-4d5d-4e6e-bd76-77b2aaa91650"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df_original"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-773818bc-935c-42a7-8c5f-253cdd7b5dda\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Markdown</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106000</td>\n",
       "      <td>0</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>5502.9669</td>\n",
       "      <td>1474.233</td>\n",
       "      <td>236.8201</td>\n",
       "      <td>14827.2141</td>\n",
       "      <td>5103.4707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106000</td>\n",
       "      <td>0</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>5502.9669</td>\n",
       "      <td>1474.233</td>\n",
       "      <td>236.8201</td>\n",
       "      <td>14827.2141</td>\n",
       "      <td>5103.4707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106000</td>\n",
       "      <td>0</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>5502.9669</td>\n",
       "      <td>1474.233</td>\n",
       "      <td>236.8201</td>\n",
       "      <td>14827.2141</td>\n",
       "      <td>5103.4707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106000</td>\n",
       "      <td>0</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>5502.9669</td>\n",
       "      <td>1474.233</td>\n",
       "      <td>236.8201</td>\n",
       "      <td>14827.2141</td>\n",
       "      <td>5103.4707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106000</td>\n",
       "      <td>0</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>5502.9669</td>\n",
       "      <td>1474.233</td>\n",
       "      <td>236.8201</td>\n",
       "      <td>14827.2141</td>\n",
       "      <td>5103.4707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551474</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>26</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>76.05</td>\n",
       "      <td>...</td>\n",
       "      <td>194.049252</td>\n",
       "      <td>8.299803</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4842.2900</td>\n",
       "      <td>975.030</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2449.9700</td>\n",
       "      <td>3169.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551475</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>27</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>77.50</td>\n",
       "      <td>...</td>\n",
       "      <td>194.118327</td>\n",
       "      <td>8.295893</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9090.4800</td>\n",
       "      <td>2268.580</td>\n",
       "      <td>582.7400</td>\n",
       "      <td>5797.4700</td>\n",
       "      <td>1514.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551476</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>28</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>79.37</td>\n",
       "      <td>...</td>\n",
       "      <td>194.187760</td>\n",
       "      <td>8.291982</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3789.9400</td>\n",
       "      <td>1827.310</td>\n",
       "      <td>85.7200</td>\n",
       "      <td>744.8400</td>\n",
       "      <td>2150.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551477</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>29</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>82.84</td>\n",
       "      <td>...</td>\n",
       "      <td>194.257397</td>\n",
       "      <td>8.288071</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2961.4900</td>\n",
       "      <td>1047.070</td>\n",
       "      <td>204.1900</td>\n",
       "      <td>363.0000</td>\n",
       "      <td>1059.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551478</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>118221</td>\n",
       "      <td>76.06</td>\n",
       "      <td>...</td>\n",
       "      <td>194.327149</td>\n",
       "      <td>8.284160</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>212.0200</td>\n",
       "      <td>851.730</td>\n",
       "      <td>2.0600</td>\n",
       "      <td>10.8800</td>\n",
       "      <td>1864.5700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551479 rows × 21 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-773818bc-935c-42a7-8c5f-253cdd7b5dda')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-773818bc-935c-42a7-8c5f-253cdd7b5dda button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-773818bc-935c-42a7-8c5f-253cdd7b5dda');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f1113b76-f1d9-4be8-a9ba-10446d41aee7\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1113b76-f1d9-4be8-a9ba-10446d41aee7')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f1113b76-f1d9-4be8-a9ba-10446d41aee7 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_2bba0f3e-4c7f-451a-b29e-b2269a8e20d5\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_original')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_2bba0f3e-4c7f-451a-b29e-b2269a8e20d5 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_original');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        Day  Month  Year  Week        Date  Store  Dept  Type    Size  \\\n",
       "0         5      2  2010     5  2010-02-05      1     1     1  151315   \n",
       "1         5      2  2010     5  2010-02-05      1     2     1  151315   \n",
       "2         5      2  2010     5  2010-02-05      1     3     1  151315   \n",
       "3         5      2  2010     5  2010-02-05      1     4     1  151315   \n",
       "4         5      2  2010     5  2010-02-05      1     5     1  151315   \n",
       "...     ...    ...   ...   ...         ...    ...   ...   ...     ...   \n",
       "551474   28      6  2013    26  2013-06-28     45    98     2  118221   \n",
       "551475    5      7  2013    27  2013-07-05     45    98     2  118221   \n",
       "551476   12      7  2013    28  2013-07-12     45    98     2  118221   \n",
       "551477   19      7  2013    29  2013-07-19     45    98     2  118221   \n",
       "551478   26      7  2013    30  2013-07-26     45    98     2  118221   \n",
       "\n",
       "        Temperature  ...         CPI  Unemployment  IsHoliday  Weekly_Sales  \\\n",
       "0             42.31  ...  211.096358      8.106000          0      24924.50   \n",
       "1             42.31  ...  211.096358      8.106000          0      50605.27   \n",
       "2             42.31  ...  211.096358      8.106000          0      13740.12   \n",
       "3             42.31  ...  211.096358      8.106000          0      39954.04   \n",
       "4             42.31  ...  211.096358      8.106000          0      32229.38   \n",
       "...             ...  ...         ...           ...        ...           ...   \n",
       "551474        76.05  ...  194.049252      8.299803          0           NaN   \n",
       "551475        77.50  ...  194.118327      8.295893          0           NaN   \n",
       "551476        79.37  ...  194.187760      8.291982          0           NaN   \n",
       "551477        82.84  ...  194.257397      8.288071          0           NaN   \n",
       "551478        76.06  ...  194.327149      8.284160          0           NaN   \n",
       "\n",
       "        Markdown  MarkDown1  MarkDown2  MarkDown3   MarkDown4  MarkDown5  \n",
       "0              0  5502.9669   1474.233   236.8201  14827.2141  5103.4707  \n",
       "1              0  5502.9669   1474.233   236.8201  14827.2141  5103.4707  \n",
       "2              0  5502.9669   1474.233   236.8201  14827.2141  5103.4707  \n",
       "3              0  5502.9669   1474.233   236.8201  14827.2141  5103.4707  \n",
       "4              0  5502.9669   1474.233   236.8201  14827.2141  5103.4707  \n",
       "...          ...        ...        ...        ...         ...        ...  \n",
       "551474         1  4842.2900    975.030     3.0000   2449.9700  3169.6900  \n",
       "551475         1  9090.4800   2268.580   582.7400   5797.4700  1514.9300  \n",
       "551476         1  3789.9400   1827.310    85.7200    744.8400  2150.3600  \n",
       "551477         1  2961.4900   1047.070   204.1900    363.0000  1059.4600  \n",
       "551478         1   212.0200    851.730     2.0600     10.8800  1864.5700  \n",
       "\n",
       "[551479 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XKWLE3p3VAB"
   },
   "source": [
    "**Filtering null values and non-null value in different dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuMTCoAp6EvD",
    "outputId": "9bf6b46b-a26f-422f-d410-1dd8f9aa9836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.null shape (131267, 21)\n",
      "2.not null  (420212, 21)\n"
     ]
    }
   ],
   "source": [
    "df_null = df_original[df_original[\"Weekly_Sales\"].isnull()]\n",
    "df_null.reset_index(drop=True, inplace=True)\n",
    "print(\"1.null shape\",df_null.shape)\n",
    "\n",
    "df = df_original[df_original[\"Weekly_Sales\"].notnull()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"2.not null \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVbh1EeS3kiy"
   },
   "source": [
    "**Removing Outliers in Weekly_Sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lKA5X9Cf6U-_"
   },
   "outputs": [],
   "source": [
    "Q1 = df['Weekly_Sales'].quantile(0.25)\n",
    "Q3 = df['Weekly_Sales'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "l = Q1 - 1.5 * IQR\n",
    "u = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[(df['Weekly_Sales'] >= l) & (df['Weekly_Sales'] <= u)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cjK5ooG3zDd"
   },
   "source": [
    "**Creating new feature -> Weekly Sales Lag.**\n",
    "\n",
    "**This feature will extract the previous week's sales Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N2gSjLNr6ZR9"
   },
   "outputs": [],
   "source": [
    "df['Weekly_Sales_Lag1'] = df['Weekly_Sales'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfOyWwPY4MsW"
   },
   "source": [
    "**1st Week's will be missing due to lag feature. So filling it with 1st week's mean value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iTwyQJEz7Bat"
   },
   "outputs": [],
   "source": [
    "df1 = df[df[\"Store\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OARP0j1D4nC0"
   },
   "source": [
    "**Selecting only appropriate features that is necessary to build a perfect model.**\n",
    "\n",
    "**Square rooting the Weekly_Sales column to reduce skewness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NSez1UMd7BVJ"
   },
   "outputs": [],
   "source": [
    "features = ['Store','Type','Size','Day', 'Month', 'Year', 'Dept', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday', 'Weekly_Sales_Lag1']\n",
    "x = df[features]\n",
    "y = df['Weekly_Sales']\n",
    "x.fillna(df1[\"Weekly_Sales_Lag1\"].mean(),inplace = True)\n",
    "y_transformed = np.sqrt(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_transformed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urZD-wQnP3A5",
    "outputId": "06789fb0-d3cb-4050-cd91-76546f1e994e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 10ms/step - loss: 2541.7988 - val_loss: 1764.6898 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 9ms/step - loss: 1881.7554 - val_loss: 1687.5079 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 10ms/step - loss: 1791.3077 - val_loss: 1593.8549 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - loss: 1731.9143 - val_loss: 1535.8954 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 9ms/step - loss: 1684.8848 - val_loss: 1488.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 9ms/step - loss: 1652.3839 - val_loss: 1402.9308 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9ms/step - loss: 1611.8757 - val_loss: 1403.4758 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9ms/step - loss: 1563.5458 - val_loss: 1307.8834 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - loss: 1529.6217 - val_loss: 1277.6847 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 9ms/step - loss: 1481.3945 - val_loss: 1206.2780 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 9ms/step - loss: 1452.5999 - val_loss: 1212.4983 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 9ms/step - loss: 1436.2993 - val_loss: 1164.0116 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 8ms/step - loss: 1407.1581 - val_loss: 1127.1143 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 8ms/step - loss: 1395.4264 - val_loss: 1111.5885 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 1374.5750 - val_loss: 1057.8679 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8ms/step - loss: 1346.4796 - val_loss: 1078.0132 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 9ms/step - loss: 1332.9457 - val_loss: 1039.0181 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - loss: 1317.2732 - val_loss: 1010.9979 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 8ms/step - loss: 1303.9806 - val_loss: 1023.6555 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8ms/step - loss: 1299.4725 - val_loss: 992.4690 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 1278.8759 - val_loss: 1003.8858 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 9ms/step - loss: 1265.2466 - val_loss: 1024.0020 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8ms/step - loss: 1250.7434 - val_loss: 979.6384 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 9ms/step - loss: 1242.4894 - val_loss: 941.7032 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 9ms/step - loss: 1228.5588 - val_loss: 914.1154 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 9ms/step - loss: 1227.0890 - val_loss: 926.7570 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 8ms/step - loss: 1215.7542 - val_loss: 913.7216 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 9ms/step - loss: 1196.4883 - val_loss: 885.4910 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 8ms/step - loss: 1196.8987 - val_loss: 883.7272 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8ms/step - loss: 1175.1721 - val_loss: 873.2443 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 1170.2029 - val_loss: 840.6700 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 9ms/step - loss: 1160.9015 - val_loss: 836.1116 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - loss: 1154.5162 - val_loss: 857.8790 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 1153.5981 - val_loss: 863.3682 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 1132.0308 - val_loss: 822.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9ms/step - loss: 1123.0366 - val_loss: 799.6266 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 9ms/step - loss: 1110.9169 - val_loss: 770.2273 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9ms/step - loss: 1109.9856 - val_loss: 793.1875 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 9ms/step - loss: 1111.2410 - val_loss: 760.0930 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 1101.4099 - val_loss: 749.7537 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 9ms/step - loss: 1088.7239 - val_loss: 768.9979 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 9ms/step - loss: 1083.7395 - val_loss: 748.0446 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8ms/step - loss: 1081.2255 - val_loss: 734.5743 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 9ms/step - loss: 1076.0928 - val_loss: 743.9703 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8ms/step - loss: 1069.2623 - val_loss: 729.1080 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 1069.7816 - val_loss: 706.2937 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8ms/step - loss: 1059.4092 - val_loss: 727.4669 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 1047.4449 - val_loss: 708.5239 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 1052.9187 - val_loss: 727.1145 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 1050.2479 - val_loss: 702.3923 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 1046.4307 - val_loss: 702.0509 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 7ms/step - loss: 1035.4406 - val_loss: 708.3590 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 8ms/step - loss: 1026.8160 - val_loss: 717.4643 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 1024.7095 - val_loss: 681.3503 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 1023.6948 - val_loss: 705.4445 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 1023.0439 - val_loss: 728.2551 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 1030.1233 - val_loss: 690.4542 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 1010.9583 - val_loss: 689.7020 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 1005.8519 - val_loss: 725.5452 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 1012.7021 - val_loss: 662.4043 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7ms/step - loss: 1006.7729 - val_loss: 663.7108 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 7ms/step - loss: 1006.5999 - val_loss: 681.2391 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8ms/step - loss: 996.7075 - val_loss: 675.8691 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 996.9630 - val_loss: 656.1189 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 987.8545 - val_loss: 649.8414 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 995.2547 - val_loss: 684.4261 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 988.1713 - val_loss: 644.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - loss: 979.3290 - val_loss: 656.3414 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8ms/step - loss: 983.8408 - val_loss: 647.9133 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 982.5398 - val_loss: 639.1791 - learning_rate: 5.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 968.7731 - val_loss: 638.1054 - learning_rate: 5.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 971.7292 - val_loss: 680.5823 - learning_rate: 5.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 970.2763 - val_loss: 638.7902 - learning_rate: 5.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 959.6107 - val_loss: 637.6382 - learning_rate: 5.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 960.7173 - val_loss: 634.8183 - learning_rate: 5.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 959.2442 - val_loss: 622.8519 - learning_rate: 5.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 953.0074 - val_loss: 626.7139 - learning_rate: 5.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 951.2556 - val_loss: 631.5479 - learning_rate: 5.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 955.3124 - val_loss: 638.5004 - learning_rate: 5.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 8ms/step - loss: 938.8035 - val_loss: 606.7692 - learning_rate: 5.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 946.9545 - val_loss: 599.2020 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 946.7779 - val_loss: 631.0867 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 948.2703 - val_loss: 613.0807 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 939.0862 - val_loss: 629.1931 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 8ms/step - loss: 940.3528 - val_loss: 618.9011 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 938.4263 - val_loss: 616.3400 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 8ms/step - loss: 948.5194 - val_loss: 615.8578 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - loss: 938.0095 - val_loss: 607.1589 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8ms/step - loss: 938.0364 - val_loss: 599.8784 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 936.3564 - val_loss: 626.8829 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 932.3727 - val_loss: 606.9476 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 874.5347 - val_loss: 552.8455 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 856.4586 - val_loss: 539.9935 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 840.4534 - val_loss: 550.3587 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 8ms/step - loss: 839.3378 - val_loss: 539.8274 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - loss: 836.6909 - val_loss: 525.8600 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 835.0331 - val_loss: 537.1716 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 836.1337 - val_loss: 530.4879 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 827.0801 - val_loss: 526.9225 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m9621/9621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - loss: 830.3693 - val_loss: 519.1280 - learning_rate: 2.5000e-04\n",
      "\u001b[1m2406/2406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "{'R2': 0.8387564271468828, 'Mean Absolute Error': 15.262690972689287, 'Mean Squared Error': 493.3542439097058, 'Root Mean Squared Error': 22.21157905034457}\n"
     ]
    }
   ],
   "source": [
    "# Defining the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model with learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mean_squared_error')\n",
    "\n",
    "# Train the model with EarlyStopping and Reducing the Learning Rate\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32, callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "])\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    'R2': r2,\n",
    "    'Mean Absolute Error': mae,\n",
    "    'Mean Squared Error': mse,\n",
    "    'Root Mean Squared Error': rmse\n",
    "}\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8aQ2Xtu57Z8"
   },
   "source": [
    "**Saving the model to find the null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DL3z06NlP2-D"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AN5F_vja0Zcm"
   },
   "outputs": [],
   "source": [
    "with open(\"deep_learning.pkl\", 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "k3VyUbU7P27G"
   },
   "outputs": [],
   "source": [
    "with open(\"scalar.pkl\",'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
